{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import unicodedata\n",
    "import html\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(\"\\r\\n\", \" \")\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"\\r\", \" \")\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    text = text.replace(u'\\xa0', u' ')\n",
    "    text.strip()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"http://www.gardening.cornell.edu/homegardening/sceneb771.html\"\n",
    "base_url = \"http://www.gardening.cornell.edu/homegardening/\"\n",
    "page = requests.get(main_url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "html_pages = []\n",
    "for link in soup.find_all('a'):\n",
    "    html_pages.append(link.get('href'))\n",
    "formatted_pages = []\n",
    "for page in html_pages:\n",
    "    if page != None and \"scene\" in str(page):\n",
    "        formatted = base_url + page\n",
    "        formatted_pages.append(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "for url in formatted_pages:\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    bolds = soup.find_all(['b'])\n",
    "    name = bolds[1].text.strip()\n",
    "    \n",
    "    data_dict = {}\n",
    "    headers = soup.find_all(['p', 'li', 'b'])\n",
    "    total_text = []\n",
    "    for head in headers:\n",
    "        total_text.append(head.text)\n",
    "\n",
    "    total_text = list(map(lambda t : clean_text(t), total_text))\n",
    "    occurs1 = occurs2 = occurs3 = occurs4 = occurs5 = occurs6 = occurs7 = occurs8 = True\n",
    "    for text in total_text:\n",
    "        if \"Germination temperature:\" in text and occurs1:\n",
    "            text = text.replace(\"Germination temperature:\", \"\").strip()\n",
    "            data_dict[\"Germ_Temp\"] = text\n",
    "            occurs1 = False\n",
    "        if \"Days to emergence:\" in text and occurs2:\n",
    "            data_dict[\"Germ_Time\"] = text.strip()\n",
    "            occurs2 = False\n",
    "        if \"Height:\" in text and occurs3:\n",
    "            text = text.replace(\"Height:\", \"\").strip()\n",
    "            data_dict[\"Height\"] = text\n",
    "            occurs3 = False\n",
    "        if \"Spread:\" in text and occurs4:\n",
    "            text = text.replace(\"Spread:\", \"\").strip()\n",
    "            data_dict[\"Spread\"] = text\n",
    "            occurs4 = False\n",
    "        if \"Lifecycle:\" in text and occurs5:\n",
    "            text = text.replace(\"Lifecycle:\", \"\").strip()\n",
    "            data_dict[\"Lifecycle\"] = text\n",
    "            occurs5 = False\n",
    "        if \"Ease-of-care:\" in text and occurs6:\n",
    "            text = text.replace(\"Ease-of-care:\", \"\").strip()\n",
    "            data_dict[\"Care\"] = text\n",
    "            occurs6 = False\n",
    "        if \"sun\" in text and occurs7:\n",
    "            data_dict[\"Sun\"] = text\n",
    "            occurs7 = False\n",
    "        if \"Soil Conditions\" in text and occurs8:\n",
    "            text = text.replace(\"Soil Conditions:\", \"\").strip()\n",
    "            data_dict[\"Soil\"] = text\n",
    "            occurs8 = False\n",
    "\n",
    "\n",
    "    combined_text = reduce(lambda s, acc : acc + s, total_text)\n",
    "    combined_text = combined_text.replace(\"\\n\", \";;\")\n",
    "    data_dict[\"Combined\"] = combined_text\n",
    "    \n",
    "    final_dict[name] = data_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"initial_plant_scrape.json\", \"w\")\n",
    "json.dump(final_dict, fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
